\documentclass{acm_proc_article-sp}
\usepackage{cite}
\usepackage{hyperref}
\hyphenation{ep-i-lep-sy}

\begin{document}
\title{Semantic Analysis of Epilepsy Patient Discharge Records}
\subtitle{A Project for EECS600: The Semantic Web}
\numberofauthors{2}
\author{
\alignauthor Ian Dimayuga \\
    \email{ian.dimayuga@case.edu}\\
\alignauthor Tom Dooner \\
    \email{tom.dooner@case.edu}\\
}
\maketitle
\begin{abstract}
We outline an application built using the Natural Language Toolkit\cite{nltk} which extracts meaningful information
from epilepsy patient discharge records. This information, designed to have high precision and recall, can be further
analyzed to determine trends across collections of records. Furthermore, we develop a simple web application frontend
to allow easy access to the backend parsing script.
\end{abstract}

\section{Introduction}

\section{Background}
The broader field of applying Natural Language Processing (NLP) to Electronic Health Records
is well-discussed in academic journals. For example, a Clinical Data Architecture has been
proposed~\cite{CDA} which promises to structure electronic health records. Unfortunately, however,
decades of health records exist digitally in an unstructured format. Lacking structure, it is
difficult to write applications which can analyze any broad collection of records. Researchers
have found it prudent to consider using NLP technology to detect medical errors, correlate data, 
and draw conclusions on vast quantities of data~\cite{friedman}.

Prior work exists in other NLP-related fields, such as evaluating how semantically similar 
two suggested medical terms are~\cite{Pedersen2007288} and how to analyze patient
discharge summaries to extract keywords and key relationships from the content of the
reports~\cite{soderland}. Perhaps the most relevant prior work is Uzuner et al., in 2006,
showed with some success that smoking status can be inferred from medical discharge 
records~\cite{Uzuner200814}.

While our goals are not to make as black-and-white a decision as Uzuner et al., we hope to take 
advantage of research contained in these referenced articles to produce a useful tool which will
help medical professionals draw conclusions by querying more-structured data.

\section{Project Goals}
Our project, as proposed, sought to accomplish the following goals.
\subsection{One Grammar, Multiple Files}
Using the same methodology, we want our technique to correctly determine attributes from a wide selection
of patient discharge reports.

Due to the short nature of this project, we were unable to obtain more than nine usable discharge reports,
so we made our goal to use these nine documents as a proof-of-concept for an extensible approach which
could apply to more discharge reports if they become available.

\subsection{Consistent Data Formatting}
In the patient discharge summaries, data is represented in plain text. While there are methods of
searching through plaintext, far more opportunities await if the data can be represented in a 
structured, meaningful format.

We seek to facilitate this improved data formatting by providing a consistent output format.
\subsection{Easy Search}
The formatted output should be easy to search. If you want to search for a captured attribute,
you should be able to in the structured output.

\section{Significance}
The national Institute of Medicine has specifically noted NLP as a catalyst for a new
standard of medical care~\cite{friedman}. New functionality can be offered that is currently
impractical due to human limitations on data access speed and correlation.

We hope that our application of NLP to the domain of patient summaries will afford the
web application users (medical professionals) with some never-before-seen insights.
Although our application will be operating on a small corpus of data with a small set 
of fields, in theory, semantically describing medicine records has wide-reaching 
significance in medicine.

\section{Prior Work}
The broader field of applying Natural Language Processing (NLP) to Electronic Health Records
is well-discussed in academic journals. For example, a Clinical Data Architecture has been
proposed~\cite{CDA} which promises to structure electronic health records. Unfortunately, however,
decades of health records exist digitally in an unstructured format. Lacking structure, it is
difficult to write applications which can analyze any broad collection of records. Researchers
have found it prudent to consider using NLP technology to detect medical errors, correlate data, 
and draw conclusions on vast quantities of data~\cite{friedman}.

Prior work exists in other NLP-related fields, such as evaluating how semantically similar 
two suggested medical terms are~\cite{Pedersen2007288} and how to analyze patient
discharge summaries to extract keywords and key relationships from the content of the
reports~\cite{soderland}. Perhaps the most relevant prior work is Uzuner et al., in 2006,
showed with some success that smoking status can be inferred from medical discharge 
records~\cite{Uzuner200814}.

While our goals are not to make as black-and-white a decision as Uzuner et al., we hope to take 
advantage of research contained in these referenced articles to produce a useful tool which will
help medical professionals draw conclusions by querying more-structured data.

\section{Methodology}
\subsection{Text Extraction}
% OCR, pdftotext -layout
When an epileptic patient is discharged from care, a Patient Discharge Summary is
filled out, detailing the patient's history, symptoms, the tests administered, as
well as diagnoses and recommended treatment. The majority of the documents are
presented in natural English language, while certain standard portions are in a
more structured format, with well-defined attributes and values. Finally, some
reports include a graphical representation of EEG data, which we excluded from analysis.
The body of data is provided as PDF scans, without text data. This necessitated the use
of Optical Character Recognition (OCR) to decipher the text from the PDF images.
After performing OCR, we used the pdftotext utility with the layout-preserving option
to extract the text data into program-readable files.

\subsection{Cleanup}
After extracting the text from the PDF documents, we remained with the complete raw text from the PDF files.
Unfortunately, this raw text includes a lot of things which might mess up later Natural Language Processing --
namely whitespace and the string \texttt{--De-identified--}, which replaces all personal data in our datasets.

Unfortunately, due to the human imperfect nature of data cleanup, the \texttt{--De-identified--} text does not remain
intact and is often spread amongst multiple words, split with spaces, and otherwise altered. Thus, after extracting
the text, we run it through a custom-written Ruby script which has a good success rate at removing instances of 
\texttt{--De-identified--} in its various forms.

Another benefit we get by preprocessing the text is the ability to break the file into sections. For instance,
all the major sections are titled with a line of all-captial letters. Using this, we can na{\"i}vely break the text
into sections which can be run individually afterwards.

To store these sections, the clean script outputs a JSON representation of a (key, value) object whose keys contain the
section heading and the values contain lists of line contents under the given key. This is read in by the parsing
script.

\subsection{Tokenization}
% sections, sentences, words
%                      words, words, words.
The tokenization process was performed in three phases. The first phase was section
recognition. Luckily, many sections in Patient Discharge Summaries have headers presented
in large capital letters, which are easy to recognize. Furthermore, the majority of
section titles are the same throughout all Summaries. The second phase was to partition
each section into sentences. This was done using the punkt tokenizer from NLTK,
which splits cleanly and intelligently along sentence-delimiting punctuation.
Third and finally, we tokenized each sentence into words.

\subsection{Tagging}
With the list of tokens (words) from the sentences, the difficulty becomes making sense of the 
document's meaning. Towards this end, we use a tagger to assign parts of speech to each
token. For instance, a basic part-of-speech tagger would assign tags like \texttt{NNP} to a
singular proper noun and \texttt{RB} to an adverb. Using these tags, it is then possible to search
for certain patterns and extract meaning.

\subsubsection{Default Tagger}
In our project we use the NLTK built-in tagger from the Penn Treebank\cite{treebank}. Trained on a
large corpus of text, the tagger classifies every token into one of thirty-six possible parts of speech. 
Anecdotally, the tagger performs well. However, since some words are mistaken, and we wish to extract 
more meaning than by simply analyzing the English phrases, we need to customize the tagger to provide more
granularity.

\subsubsection{Medicine Tagger}
To this end, we used two additional chunkers to be used with the NLTK, a custom \textit{MedicineTagger} and
a rule-based \textit{RegexpTagger}. The former tagger searches for an key in a hash table and returns the tag
\texttt{DRUG} when the key is in the hash table. When inputted with a list of FDA-approved medicines, the
\textit{MedicineTagger} will create the hash table and output the desired \texttt{DRUG} tag when a given token
matches a drug name on the FDA's list.

\subsubsection{Regular Expression Tagger}
When the \textit{MedicineTagger} is unable to tag an item, the process falls back upon the secondary tagger, the
\textit{RegexpTagger} -- a regular-expression based tagger. Using only 20 custom rules, we were able to add enough
additional semantic meaning to tokens to facilitate data extraction in later steps.

If the token does not match a medicine with the \textit{MedicineTagger} and doesn't match any rule in the
\textit{RegexpTagger}, then the token falls back to the Default Penn Treebank tagger. In this way, every token will
receive the most semantically meaningful tag possible.

\subsection{Chunking}
Once each token has been tagged, we used a custom-built grammar to parse and chunk
the text. It is useful to chunk tagged tokens, for instance, to generate a meaningful chunk of
semantic data. To chunk tokens, we iterate through the list of tagged tokens and apply a series
of custom regular-expression productions using NLTK's \textit{RegexpParser}. Overall, we wrote
twenty-four productions.

The majority of productions dealt specifically with finding and parsing
sentences about prescription regimens, episodic semiology, comorbidity, and epileptogenic
zones. Although some of this data was presented in structured list format, extracting it using
chunking and parsing proved non-trivial. Compounding on this difficulty, our 
small dataset provided a limitation in creating an approach which scales to unseen documents.

Although we have tested our approach (with much success) on our nine-document dataset and have found it
to be flexible, in the future it will be necessary
to use both a larger dataset and a more general grammar to glean further semantic
data from the Discharge Summaries.
\subsection{Entity Recognition}
\section{Future Work}
% augment our grammar with a more general grammar
% study a larger dataset
As previously mentioned, we were provided with a very limited number of actual Discharge
Summaries, which were further constricted by the De-Identification. To be specific,
our data domain consisted of nine (9) reports. The one advantage to this is that we
had in our hands a very manageable amount of data from which to derive our domain-
specific grammar. However, a dataset like this did not lend itself to testing. In
the future, we hope to acquire a much larger number of Patient Discharge Summaries.
Given those, we can do one of two things. The first option is to generalize our grammar
and perhaps augment it with some more general English productions. The second option,
given a sufficiently large and diverse dataset, is to implement a stochastic grammar
that can adjust to more data as it arrives.

Furthermore, it would be very useful to have data that is \emph{anonymized} rather
than simply de-identified, with names and other identifying information replaced
with arbitrary and non-private but still relevant information, rather than simply
censored with gray rectangles and poorly formatted, irrelevant words. This will allow
us to account for the tokens and productions that appear in those areas, rather than
having to pretend they don't exist.

In the future, we hope to be able to provide healthcare professionals with up-to-date,
useful, and semantically-rich information on patients with epilepsy. With enough
existing data, and the ability to adapt to additional data, we will be able to develop
a system that can point researchers in the field in the right direction to find patients
relevant to the needs of their research.
\section{References}
\bibliography{citations}{}
\bibliographystyle{plain}
\end{document}
